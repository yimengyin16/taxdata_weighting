---
title: "State TaxData Enhancement Project -- Task 2"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_notebook: 
    df_print: paged
    toc: yes
    toc_depth: 5
    number_sections: true
editor_options: 
  chunk_output_type: console
---

<!--
  Enclose comments for RMD files in these kinds of opening and closing brackets
-->



# Start of the program

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, message=FALSE)
```


```{r system_specific_info, include=TRUE}
# change information here as needed
destdir <- "C:/Dropbox/AA_Projects_Work/Proj_taxData/Data/acs/"

#dbdir <- paste0(destdir, "rsqlite/") # location for sqlite database to be created
#dbf <- paste0(dbdir, "acs.sqlite") # database name; database will be created (if not already created) and used below

```


```{r includes, include=FALSE}
source(here::here("task2", "libraries_djb.r"))
source(here::here("task2", "functions_djb.r"))
source(here::here("task2", "functions_optimization_djb.r"))
source(here::here("task2", "functions_ipoptr.R"))
```


# Constructing a subset of ACS data

```{r}

persons_all <- readRDS(paste0(destdir, "persons.rds"))
glimpse(persons_all)
ns(persons_all)

states_select <- c("NY", "NY", "TX", "IL", "FL") # 5 large very different states
n_sample      <- 50e3
set.seed(1234)

acs_subset <- persons_all %>% 
  filter(stabbr %in% states_select, !is.na(pincp), agep >= 18) %>% 
  sample_n(n_sample) %>% 
  select(-st) %>% 
  mutate(otherincp = pincp - (intp + pap + retp + ssip + ssp + wagp),
         weightp   = pwgtp) # equal to original pwgt, for constructing constraints

glimpse(acs_subset)


saveRDS(acs_subset, paste0(PROJHOME, "/data/acs_subset.rds"))

glimpse(acs_subset)
ht(acs_subset)
summary(acs_subset)

# count(samp, stabbr) %>% mutate(share = 100 * n / sum(n))
# count(persons_all, stabbr) %>% filter(stabbr %in% states_select) %>% mutate(share = 100 * n / sum(n))
# 
# count(samp, sex) %>% mutate(share = 100 * n / sum(n))
# persons_all %>% filter(stabbr %in% states_select) %>% count(sex) %>% mutate(share = 100 * n / sum(n))
# 
# quantile(samp$agep)
# quantile(persons_all %>% filter(stabbr %in% states_select, agep>=18) %>% pull(agep))
# 
# quantile(samp$pincp)
# quantile(persons_all %>% filter(stabbr %in% states_select, agep>=18) %>% pull(pincp))
# quantile(persons_all %>% filter(agep>=18) %>% pull(pincp))
# 


## Key variable 

# serialno: family ID
# sporder : family member ID
# stabbr  : state abbreviation
# pwgtp   : person weight, an integer NOTE: do not need to be divided by 100 as in the case of PUF
# sex
# agep    : age
# mar
# intp    : interest income 
# pap     : public assistance income
# pincp   : total person income
# retp    : retirement income
# ssip    : Supplemental Security Income
# ssp     : Social Security income
# wagp    : Wages

#------------------------------------------


### Original instruction
# # keep a few variables:
# # RECID unique id
# # E00100 AGI
# # E00200 wages
# # E00300 interest received -- not kept
# # E01700 pension income in AGI
# # E02000 schedule E net income 
# # S006 record weight as an integer - must be divided by 100
# vars <- c("RECID", "E00100", "E00200", "E01700", "E02000", "S006")
# set.seed(1234)
# pufsub <- pufraw %>% 
#   sample_n(5000) %>%
#   select(vars) %>%
#   mutate(weight=S006 / 100, otheragi=E00100 - E00200 - E01700 - E02000) %>%
#   select(-S006) %>%
#   select(RECID, weight, everything())
# 
# # glimpse(pufsub)
# # ht(pufsub)

```


# Setting target state and preparing recipe for constraint coefficients

```{r}
# Loading data
acs_subset <- readRDS(paste0(PROJHOME, "/data/acs_subset.rds"))
ht(acs_subset)

# Set target state
target_state <- "NY"  # "CA", "NY", "TX", "IL", "FL"


# Choose objective function

obj_fn <- c("xtop", "absapprox")[2]



# create a recipe that says which ccoef's we want.

# As before, we want a df with 3 columns:
#  vname:     a character variable name
#  valgroup:  a character variable with a logical expression defining the data subgroup
#  fn:        a character variable giving a function name (or calculation label)
#             right now, the function get_ccoefs has definitions for sumval, npos, and nnegs
#             so that's what we'll use, but we could expand it of course

# Create a sub-recipe for file totals - must make sure valgroup is character 

totals_recipe <- read_csv("
  vname, valgroup, fn
  weightp, TRUE, npos
  pincp, TRUE, sumval
  pincp, TRUE, npos
  wagp,  TRUE, sumval
  intp,  TRUE, sumval
  intp,  TRUE, npos
  retp,  TRUE, sumval
  retp,  TRUE, npos
  ssp,   TRUE, sumval
  ssp,   TRUE, npos", col_types = cols(.default=col_character()))
totals_recipe


# Create a sub-recipe for pincp ranges
# Here we'll define pincp ranges seperately, for convenience
# There may be more efficient (less labor-intensive) ways to do this...

# 5 pincp ranges

# acs_subset$pincp %>% quantile(c(0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1)) # percentiles of the subset 
# persons_all$pincp[persons_all$stabbr %in% states_select & persons_all$agep >= 18 ] %>% quantile(c(0, 0.01, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1), na.rm = TRUE) # percentiles of the whole dataset
pincp_ranges <- read_csv("
pincprange
pincp<=0
pincp>0&pincp<=25e3
pincp>25e3&pincp<=50e3
pincp>50e3&pincp<=100e3
pincp>100e3")
pincp_ranges

vnames <- c("weightp",  "pincp",  "wagp", "intp", "retp", "ssp") #[c(1,2,3, 4)]
fns    <- c("sumval", "npos", "nneg")         #[c(1,2,3)]

# We are setting things up to define 5 x 4 x 3 = 60 constraints, here goes:
range_recipe <- expand_grid(vname = vnames, valgroup=pincp_ranges$pincprange, fn = fns)

# Excluding some constraints
range_recipe %<>%
    filter(!(vname == "weightp" & fn %in% c("sumval", "nneg"))) %>% # some of coeffs of npos is the total weight
    filter(!(vname == "ssp"     & fn %in% c("nneg")))
#   filter(!(vname == "pincp" & valgroup %in% c("pincp<=0"))) %>% 
#   filter(!(vname == "wagp" & valgroup %in% c("pincp<=0"))) %>% 
#   filter(!(vname == "retp" & valgroup %in% c("pincp<=0"))) %>% 
#   filter(!(vname == "intp" & valgroup %in% c("pincp<=0"))) %>% 
#   filter(!(vname == "intp" & fn %in% c("nneg"))) %>% # including sumval leads to failure 
#   filter(!(vname == "retp" & fn %in% c("npos", "nneg")))     # including sumval leads to failure 

range_recipe


# now combine the two sub recipes
recipe <- bind_rows(totals_recipe, range_recipe) %>% 
#recipe <- totals_recipe %>% 
  mutate(constraint_sort = row_number(),
         constraint_name = paste(vname, str_remove_all(valgroup, " "), fn, sep="_")) %>%
  select(constraint_sort, everything())
  
recipe

# Checking the number of constraints and nuber of non-zero coeffs
ccoef_sparse_test <- recipe %>% 
  rowwise() %>% 
  do(get_ccoefs(., acs_subset)) %>% 
  ungroup
count(ccoef_sparse_test, constraint_sort, constraint_name)

ccoef_lowN_test <- # constraints with low # of non-zero coefficients 
  count(ccoef_sparse_test, constraint_sort, constraint_name) %>% 
  filter(n <= nrow(acs_subset) / 1000)
ccoef_lowN_test

ccoef_sparse_test %<>% 
  filter(!constraint_name %in% ccoef_lowN_test$constraint_name) %>% 
# ONLY AFTER all filtering is done do we assign constraint numbers, as some
  # may drop out if they have no nonzero coefficients %>%
  mutate(constraint_num = group_indices(., constraint_sort)) %>%
  arrange(constraint_num, row_num) %>% 
  select(constraint_num, everything())

count(ccoef_sparse_test, constraint_num, constraint_sort, constraint_name)
```


```{r}
run_ipopt <- function(target_state,
                      recipe,
                      obj_fn,
                      data = acs_subset){
# Function inputs
#  - target_state
#  - acs_subset
#  - recipe
#  - obj_fn

# data <- acs_subset

    
# # names(persons_all)
# data_use[data_use$ssp >= 0, ] %>% nrow


# Preparing ACS data for optimzation problem
 # Scale down the weights in data so that the sum of weights equals the sum of 
 # weights of the target state

totwgt_data  <- data$pwgtp %>% sum
totwgt_targetState <- filter(data, stabbr == target_state)$pwgtp %>% sum
totwgt_data; totwgt_targetState

(wgt_factor <- totwgt_targetState / totwgt_data)


data_use <- 
  data %>% 
  rename(pwgtp_original = pwgtp) %>% 
  mutate(pwgtp = pwgtp_original * wgt_factor,
         weightp = pwgtp # to construct constraints on total weight
         )


# Constructing constraint coefficient df from recipe

ccoef_sparse <- recipe %>% 
  rowwise() %>% 
  do(get_ccoefs2(., data_use)) %>% 
  ungroup
# count(ccoef_sparse, constraint_sort, constraint_name)

ccoef_lowN <- # constraints with low # of non-zero coefficients 
  count(ccoef_sparse, constraint_sort, constraint_name) %>% 
  filter(n <= nrow(data_use) / 1000)
# ccoef_lowN

ccoef_sparse %<>% 
  filter(!constraint_name %in% ccoef_lowN$constraint_name) %>% 
# ONLY AFTER all filtering is done do we assign constraint numbers, as some
  # may drop out if they have no nonzero coefficients %>%
  mutate(constraint_num = group_indices(., constraint_sort)) %>%
  arrange(constraint_num, row_num) %>% 
  select(constraint_num, everything())
# count(ccoef_sparse, constraint_num, constraint_sort, constraint_name)



# Note that we defined x constraints but only y of them have nonzero constraint coefficients. Some things dropped out. For example, in the sparse   version there are no constraints for number of returns with negative wages because there are zero records where wages are negative. Thus, there are no possible adjustments to weights that would get us negative wages.

# Now that we have a recipe let's create some targets that are slightly perturbed. In an actual analysis, we would have targets that we constructed from actual data or else from forecasts.



# Defining constraint targets 

x0 <- rep(1, nrow(data_use))

input_target <- list(); input_target$ccoef_sparse <- ccoef_sparse
constraint_vals_allstates <- input_target$ccoef_sparse %>% 
  group_by(stabbr, constraint_num) %>% 
  summarise(constraint_val = sum(ccoef / wgt_factor)) # need to use the orginal weight
# constraint_vals_allstates


state_names <- as.character(data$stabbr) %>% unique %>% sort
constraint_vals_allstates <- 
  expand.grid(stabbr = state_names, constraint_num = 1:max(ccoef_sparse$constraint_num)) %>% 
  left_join(constraint_vals_allstates) %>% 
  mutate(constraint_val = ifelse(is.na(constraint_val), 0, constraint_val)) %>% 
  arrange(stabbr, constraint_num)

# constraint_vals_allstates

target_single_state <- (constraint_vals_allstates %>% filter(stabbr == target_state) %>% pull(constraint_val))
# target_single_state
# fo
input_all <- list(); input_all$ccoef_sparse <- ccoef_sparse
init_vals            <- eval_g_sparse(x0, input_all)


# comparing target state and file value
# ccoef_sparse %>% count(constraint_num, constraint_name) %>% 
#   mutate(target_single_state = target_single_state,
#          init_vals  = init_vals ,
#          ratio = target_single_state / init_vals)



# Inputs for the function

inputs_full <- list()
inputs_full$p <- 2
inputs_full$s      <- 0.01
inputs_full$weight <- data_use$pwgtp
inputs_full$ccoef_sparse <- ccoef_sparse
inputs_full$jac_vector <- jac_flatten_sparse(inputs_full$ccoef_sparse)

inputs_full$target_state <- target_state
inputs_full$wgt_factor   <- wgt_factor
inputs_full$target_single_state <- target_single_state

# create vectors with constraint lower bounds and upper bounds - if they are the same, we have equality constraints
# create vectors with constraint lower bounds and upper bounds
# define tolerance - for simplicity, use the same for all, but that is not necessary
tol <- .01 # 2% range

clb <- target_single_state
clb <- clb - tol * abs(clb)

cub <- target_single_state
cub <- cub + tol * abs(clb)
#cbind(init_vals, target_single_state, clb, cub)

# structure of Jaobian
eval_jac_g_structure_sparse <- define_jac_g_structure_sparse(inputs_full$ccoef_sparse)

# structure of Hessian
eval_h_structure <- hess_structure(length(inputs_full$weight))

# set arbitrary bounds for x that fall inside the solution above
xlb <- rep(0.3,  length(inputs_full$weight))
xub <- rep(30, length(inputs_full$weight))

opts <- list("print_level" = 0,
             "file_print_level" = 5, # integer
             "linear_solver" = "ma27", # mumps pardiso ma27 ma57 ma77 ma86 ma97
             "max_iter"=1000)

opts$output_file <- paste0(PROJHOME, "/task2/results/prob_NY.out")
opts$obj_scaling_factor <- 1 # default 1 
opts$nlp_scaling_max_gradient <- 100 # default 100 -- not changing this now
#opts  


# Choosing objective function

# obj_fn <- c("xtop", "absapprox")[2]

if(obj_fn == "xtop"){
  eval_f_select           = eval_f_xtop          # function, arguments: x, inputs
  eval_grad_f_select      = eval_grad_f_xtop     # function, arguments: x, inputs
  eval_h_select           = eval_h_xtop          # function, arguments: x, inputs, (obj_factor, hessian_lambda)
}

if(obj_fn == "absapprox"){
  eval_f_select           = eval_f_absapprox          # function, arguments: x, inputs
  eval_grad_f_select      = eval_grad_f_absapprox     # function, arguments: x, inputs
  eval_h_select           = eval_h_absapprox          # function, arguments: x, inputs, (obj_factor, hessian_lambda)
}



result <- ipoptr(x0 = x0,
                 lb = xlb,
                 ub = xub,
                 
                 eval_f           = eval_f_select,          # function, arguments: x, inputs
                 eval_grad_f      = eval_grad_f_select,     # function, arguments: x, inputs
                 eval_h           = eval_h_select,          # function, arguments: x, inputs, (obj_factor, hessian_lambda)
                
                 
                 eval_h_structure = eval_h_structure,     # list, structure of Hessian
                 
                 eval_g = eval_g_sparse,                  # function, constraints LHS - a vector of values, arguments: x, inputs
                 eval_jac_g = eval_jac_g,                 # function, extract inputs$jac_vector, arguments: x, inputs
                 eval_jac_g_structure = eval_jac_g_structure_sparse, # list, structure of Jacobian
                 
                 constraint_lb = clb, 
                 constraint_ub = cub,
                 
                 opts   = opts,
                 inputs = inputs_full
                 )
 
 
 cat(result$message)
 cat("status:", result$status) 
 cat("iterations: ", result$iterations)
 cat("Distribution of the solution:","\n")
 print(quantile(result$solution, probs = c(0, .05, .1, .25, .5, .75, .9, .95, 1)))
 
 # names(output$result) %>% sort

 calcsums <- eval_g_sparse(x=result$solution, inputs_full)
 comparison <- cbind(init_vals, target_single_state, calcsums, calcsums/target_single_state)
 rownames(comparison) <- ccoef_sparse %>% count(constraint_num, constraint_name) %>% pull(constraint_name)
 # comparison
 
 outputs <- list()
 outputs$inputs <- inputs_full
 outputs$result <- result
 outputs$comparison <- comparison
 
 return(outputs)
 
}


# output <- run_ipopt("NY", recipe, "xtop")

# output$result$message; output$result$status; output$result$iterations
# output$result$objective
# quantile(output$result$solution, probs = c(0, .05, .1, .25, .5, .75, .9, .95, 1))
# result_single_state <- result
  


```




# Comparing the re-weighted data with the true single state data

1.  distributions of individual variables 
2.  covariance matrix


```{r compare percentiles}
# Examine distributions of individual variables 

compare_ptiles <- function(var_,
                           target_state_,
                           datause_,
                           result_,
                           pts = c(0, .05, .1, .25, .5, .75, .9, .95,.99, 1)
                           ){

# var_     <- "pincp"
# datause_ <- acs_subset_use
# result_  <- result_single_state
# target_state_ <- "NY"
# pts <- c(0, .05, .1, .25, .5, .75, .9, .95, 1)

datause_ %<>% 
  mutate(x = result_$solution,
         pwgtp_rewgt = pwgtp * x 
         )

data_single_state <- 
  datause_ %>% 
  filter(stabbr == target_state_)

comparison <- 
  bind_rows(
    Hmisc::wtd.quantile(datause_[[var_]], datause_$pwgtp, pts),                                      # w/ original weight
    Hmisc::wtd.quantile(data_single_state[[var_]], data_single_state$pwgtp_original, pts), # target
    Hmisc::wtd.quantile(datause_[[var_]], datause_$pwgtp_rewgt, pts)                       # reweighted
) %>% 
  mutate(var  = var_, 
         type = c("org", paste0("tgt_", target_state_) , paste0("rwt_", target_state_))) %>% 
  select(var, type, everything())

return(comparison)
}


compare_ptiles("pincp", target_state, acs_subset_use, result_single_state)
compare_ptiles("wagp",  target_state, acs_subset_use, result_single_state)
compare_ptiles("intp",  target_state, acs_subset_use, result_single_state)
compare_ptiles("retp",  target_state, acs_subset_use, result_single_state)
compare_ptiles("ssp",   target_state, acs_subset_use, result_single_state)

# Not constrained
compare_ptiles("pap",   target_state, acs_subset_use, result_single_state) # close to the original, does not fit well
compare_ptiles("ssip",  target_state, acs_subset_use, result_single_state) # close to the original, does not fit well
```


```{r compare_ecdf}
compare_ecdf <- function(var_,
                         target_state_,
                         datause_,
                         result_,
                         cutoff = 0.95){
  
# var_     <- "pap"
# datause_ <- acs_subset_use
# result_  <- result_single_state
# target_state_ <- "NY"
# cutoff <- 0.95

datause_ %<>% 
  mutate(x = result_$solution,
         pwgtp_rewgt = pwgtp * x 
         )

data_single_state <- 
  datause_ %>% 
  filter(stabbr == target_state_)
    
ecdf_org <- Hmisc::wtd.Ecdf(datause_[[var_]], datause_$pwgtp)
ecdf_tgt <- Hmisc::wtd.Ecdf(data_single_state[[var_]], data_single_state$pwgtp_original)
ecdf_rwt <- Hmisc::wtd.Ecdf(datause_[[var_]], datause_$pwgtp_rewgt)


bind_rows(
 as_tibble(ecdf_org) %>% mutate(type = "org"),
 as_tibble(ecdf_tgt) %>% mutate(type = paste0("tgt_", target_state_)),
 as_tibble(ecdf_rwt) %>% mutate(type = paste0("rwt_", target_state_))
) %>% 
  mutate(type = factor(type, levels = c("org", paste0("tgt_", target_state_), paste0("rwt_", target_state_)))) %>% 
  filter(ecdf <= cutoff) %>% 
  ggplot(aes(x = x, y = ecdf, color = type)) + theme_bw() + 
  geom_line() +
  coord_cartesian(ylim = c(0,1))+
  scale_color_manual(values = c("grey40", "red", "blue"))+
  labs(x = NULL,
       title = paste0("Comparing ECDF \nTarget state: ", target_state_, "\nVariable: ", var_))
}

compare_ecdf("pincp", target_state, acs_subset_use, result_single_state)
compare_ecdf("wagp", target_state, acs_subset_use, result_single_state)
compare_ecdf("intp", target_state, acs_subset_use, result_single_state)
compare_ecdf("retp", target_state, acs_subset_use, result_single_state)
compare_ecdf("ssp", target_state, acs_subset_use, result_single_state)

# Not constrained 
compare_ecdf("pap",  target_state, acs_subset_use, result_single_state, 1)
compare_ecdf("ssip", target_state, acs_subset_use, result_single_state, 1)



# Note
#  - negative interest income in IL


```


```{r correlation}


var_     <- "pincp"
datause_ <- acs_subset_use
result_  <- result_single_state
target_state_ <- "NY"

datause_ %<>% 
  mutate(x = result_$solution,
         pwgtp_rewgt = pwgtp * x 
         )

data_single_state <- 
  datause_ %>% 
  filter(stabbr == target_state_)

cor_org <- weights::wtd.cors(select(datause_, pincp, wagp, intp, retp, ssp) %>% as.matrix, weight = datause_$pwgtp)
cor_tgt <- weights::wtd.cors(select(data_single_state, pincp, wagp, intp, retp, ssp) %>% as.matrix, weight = data_single_state$pwgtp_original)
cor_rwt <- weights::wtd.cors(select(datause_, pincp, wagp, intp, retp, ssp) %>% as.matrix, weight = datause_$pwgtp_rewgt)

cor_org
cor_tgt
cor_rwt

# Improvement for correlation between pincp and other vars. 
# Correlation between other vars are quite low. 
# Note that these only reflect linear relationships. 



```




```{r}
# run all states and save results

outputs_NY <- run_ipopt("NY", recipe, "xtop")
outputs_CA <- run_ipopt("CA", recipe, "xtop")
outputs_TX <- run_ipopt("TX", recipe, "xtop")
outputs_IL <- run_ipopt("IL", recipe, "xtop")
outputs_FL <- run_ipopt("FL", recipe, "xtop")


saveRDS(outputs_NY, file = paste0(PROJHOME, "/task2/results/ipopt_single_NY.rds"))
saveRDS(outputs_CA, file = paste0(PROJHOME, "/task2/results/ipopt_single_CA.rds"))
saveRDS(outputs_TX, file = paste0(PROJHOME, "/task2/results/ipopt_single_TX.rds"))
saveRDS(outputs_IL, file = paste0(PROJHOME, "/task2/results/ipopt_single_IL.rds"))
saveRDS(outputs_FL, file = paste0(PROJHOME, "/task2/results/ipopt_single_FL.rds"))


```












